{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Live shared task\n",
    "\n",
    "The challenge is to build a sentence-level classifier for identyfing [adverse drug events](https://en.wikipedia.org/wiki/Adverse_event) in 60 minutes. You are free to use any data and annotation strategy you think best trades off hacking and labelling. Just please don't look at the test data.\n",
    "\n",
    "Some strategies to consider:\n",
    "* Get started with random or query-driven sampling.\n",
    "* Use the dev data for seeding learning instead of generalisation testing and analysis.\n",
    "* Tune classifier choice, hyperparameters or feature extraction.\n",
    "* Use error analysis over the dev data to refine your strategy.\n",
    "* Active learning by uncertainty or ensembles.\n",
    "* Collect 10 or more query functions and use as snorkel labelling functions.\n",
    "* Find additional data, e.g., [Twitter](https://archive.org/details/twitterstream).\n",
    "* Interactive web search or [Reddit queries](http://minimaxir.com/2015/10/reddit-bigquery/).\n",
    "* Use external data (e.g., [MAUDE](https://www.fda.gov/MedicalDevices/DeviceRegulationandGuidance/PostmarketRequirements/ReportingAdverseEvents/ucm127891.htm)) for querying or labelling functions.\n",
    "\n",
    "Please don't use data from the following as they are sources of our held-out data:\n",
    "* CSIRO CADEC data set\n",
    "* AskaPatient\n",
    "* DIEGO Lab Twitter data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dev data\n",
    "dev = Dataset.from_csv('../shared-task/dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pool data\n",
    "\n",
    "Now let's load the unlabelled pool data. We have data from several sources:\n",
    "* `aska` - Posts for additional drugs from AskaPatient\n",
    "* `ader` - Comments mentioning the same drugs from Reddit\n",
    "* `adeb` - Tweets mentioning the same set of drugs\n",
    "* `adrc` - Tweets mentioning an overlapping set of drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unlabelled data pools\n",
    "aska = Dataset.from_csv('../shared-task/aska.csv')\n",
    "ader = Dataset.from_csv('../shared-task/ader.csv')\n",
    "adeb = Dataset.from_csv('../shared-task/adeb.csv')\n",
    "adrc = Dataset.from_csv('../shared-task/adrc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data programming \n",
    "\n",
    "One view of data programming is that it takes the query functions we used in the previous exercise and uses them for weak supervision. It does this by pooling labelling function output using weighted voting.\n",
    "\n",
    "A simple implementation could use the inter-annotator agreement scripts from exercise 1.1 to weight each labelling function by its average agreement score.\n",
    "\n",
    "In the setting here, where we have dev data, we could also weight each labelling function by its perforamance on the labelled dev data. Of course, this wouldn't work in an annotation setting where we were starting without labelled data.\n",
    "\n",
    "A key difference with `snorkel` is that this approach in the annotation framework does not go on to train the classifier on a continuous voting confidence value.\n",
    "\n",
    "Feel free to experiment with voting, or use `snorkel` directly. If you do plan to use `snorkel`, note that it takes a while to [install](https://github.com/HazyResearch/snorkel#installation). It would be a good idea to run the installation in the background while you start annotating and/or writing labelling functions.\n",
    "\n",
    "Once `snorkel` is installed, the tutorials should help get things up and running. These are in the repo and can also be viewed [on github](https://github.com/HazyResearch/snorkel/tree/master/tutorials/intro)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short strategy description\n",
    "\n",
    "Before submitting, please summarise:\n",
    "* The hacking/labelling strategy you followed\n",
    "* How do you rate this strategy? Why?\n",
    "\n",
    "TODO Add your summary right here.\n",
    "\n",
    "TODO If you have a list sampling strategies, please include it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Submit your annotation and system output for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run current classifier on the dev and test data.\n",
    "# TODO classify dev data\n",
    "dev_preds = dev.copy\n",
    "for \n",
    "# TODO load test data and classify\n",
    "test_preds = Dataset.from_csv('../shared-task/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save annotations to csv\n",
    "! mkdir -p ../submissions/YOUR_USERNAME_HERE\n",
    "pool.to_csv('../submissions/YOUR_USERNAME_HERE/pool.csv')\n",
    "# save system output to csv\n",
    "dev.to_csv('../submissions/YOUR_USERNAME_HERE/dev.csv')\n",
    "test.to_csv('../submissions/YOUR_USERNAME_HERE/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy your notebook to your submission directory\n",
    "! cp exercise_2.ipynb ../submissions/YOUR_USERNAME_HERE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push your submission back to the repo\n",
    "! git add ../submissions/YOUR_USERNAME_HERE\n",
    "! git commit -m 'Checkpoint YOUR_USERNAME_HERE' ../submissions/YOUR_USERNAME_HERE/\n",
    "! git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
