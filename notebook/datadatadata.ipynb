{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: DataDataData\n",
    "\n",
    "Here's a sample class wrapping the main abstraction, the `Dataset`.\n",
    "\n",
    "* TODO Support for multiple users? @ben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import build_sample_corpus, Dataset\n",
    "train = build_sample_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Annotation & reliability\n",
    "\n",
    "* TODO Learning curve @ben\n",
    "* TODO Agreement @ben\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplers\n",
    "\n",
    "For example, a random unlabelled sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually label some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc093864fad43608060c0151e6434fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Yes', style=ButtonStyle()), Button(description='No', style=ButtonStyle()))), HTML(value=\"<p>From: yongje@hardy.u.washington.edu (Yong Je Lim)\\nSubject: Dealer cheated me with wrong odometer reading. Need help!\\nOrganization: University of Washington, Seattle\\nLines: 14\\nDistribution: usa\\nNNTP-Posting-Host: hardy.u.washington.edu\\n\\nHere is a story.  I bought a car about two weeks ago.  I finally can\\nget hold of the previous owner of the car and got all maintanence\\nhistory of the car.  In between '91 and '92, the instrument pannel \\nof the car has been replaced and the odometer also has been reset\\nto zero.  Therefore, the true meter reading is the reading before\\nreplacement plus current mileage.  That shows 35000 mile difference\\ncomparing to the mileage on the odometer disclosure from.  The \\ndealer never told me anything about that important story.\\n\\nI hope that I can return the car with full refund.  Do u think this\\nis possible?  Does anyone have similar experiences?  Any comments\\nwill be appreciated.  Thanks.\\n\\nyongje@u.washington.edu \\n</p>\")))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from annotator import AnnotationPane\n",
    "from samplers import Random\n",
    "pane = AnnotationPane(train, Random(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See our new labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None: 11197, False: 113, True: 4}\n"
     ]
    }
   ],
   "source": [
    "print(train.label_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1: Active learning\n",
    "\n",
    "Here is a straw man active sampler that:\n",
    "* trains a classifier on the labelled data\n",
    "* predicts the labels of unlabelled data\n",
    "* selects text with a specific label profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 117 labelled samples\n",
      "Cross-validating\n",
      "Cross-validated accuracy: 0.95 (+/- 0.04)\n",
      "Refitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wradford/repos/personal/alta17active/.venv/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/wradford/repos/personal/alta17active/.venv/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/wradford/repos/personal/alta17active/.venv/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/wradford/repos/personal/alta17active/.venv/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 11197 unlabelled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wradford/repos/personal/alta17active/.venv/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5782e1ea6bca4965b45532c0f202f083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Yes', style=ButtonStyle()), Button(description='No', style=ButtonStyle()))), HTML(value='<p>From: roby@chopin.udel.edu (Scott W Roby)\\nSubject: Re: BATF/FBI Murders Almost Everyone in Waco Today! 4/19\\nNntp-Posting-Host: chopin.udel.edu\\nOrganization: University of Delaware\\nLines: 45\\n\\nIn article <1993Apr20.195636.17742@guinness.idbsu.edu> betz@gozer.idbsu.edu (Andrew Betz) writes:\\n>In article <C5sou8.LnB@news.udel.edu> roby@chopin.udel.edu (Scott W Roby) writes:\\n>>>Watch from where?  Two miles away?  Far enough away that whatever\\n>>>really happenned must be explained through the vengeful filter of\\n>>>a humiliated agency that said (quote!) \"Enough is enough.\"\\n>>\\n>>Please tell me what you think would have happened had the people \\n>>come out with their hands up several weeks ago.\\n\\nNo answer.\\n\\n>You didn\\'t answer the question.  The FBI took people out of\\n>camera range.  It is thus possible that they were engaging in\\n>questionable activities.\\n\\nI do not feel like the cameras were out of range.  Cameras watched the first \\nconfrontation.  Cameras watched the banners.  Cmaeras watched the final \\nconfrontation with tanks.  Cameras watched the fire.  When weren\\'t cameras \\nable to watch?  When would cameras be unable to watch people coming out with \\ntheir hands up?\\n\\n>As to your question, please tell me what you think would have happened\\n>had the ATF goon squad knocked and asked politely several weeks\\n>ago (as opposed to playing Rambo with a t.v. crew in tow).\\n\\nWell, that is what BATF should have done.  Either, Koresh would have gone \\npeaceably as he has done in the past, or perhaps it was already too close \\nto the apocalypse in his own mind.  It is hard to predict the actions of \\na leader who would not release the children when most rational people would.\\n\\nNow will you answer my question up top?\\n\\n>\\n>Drew\\n>--\\n>betz@gozer.idbsu.edu\\n>*** brought into your terminal from the free state of idaho ***\\n>*** when you outlaw rights, only outlaws will have rights   ***\\n>*** spook fodder: fema, nsa, clinton, gore, insurrection, nsc,\\n>    semtex, neptunium, terrorist, cia, mi5, mi6, kgb, deuterium\\n\\n\\n-- \\n\\n\\n</p>')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from classifier import train_classifier\n",
    "from samplers import Active\n",
    "\n",
    "labelled = ((text, label) for text, label in train if label in {True, False})\n",
    "pipeline = train_classifier(labelled, cv=3)\n",
    "pane = AnnotationPane(train, Active(pipeline, \n",
    "                                    accept=lambda pred: pred[True] > 0.8,\n",
    "                                    limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None: 11197, False: 113, True: 4}\n"
     ]
    }
   ],
   "source": [
    "print(train.label_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Live shared task\n",
    "\n",
    "We can weakly supervise using precise functions. Note that we have no fancy model above the labelling functions.\n",
    "\n",
    "* TODO Incorporate `snorkel` @ben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../submissions/username\n",
    "! cp Shared\\ task.ipynb ../submissions/username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a new dataset (`data`) from the central data pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_csv('../shared-task/data.txt')\n",
    "data.add_label('foo', True)\n",
    "data.add_label('bar', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write back current dataset to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../submissions/username/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contribute back to the shared task pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master f2a6eb8] Checkpoint username\n",
      " 1 file changed, 32 insertions(+)\n",
      " create mode 100644 submissions/username/Shared task.ipynb\n",
      "Counting objects: 5, done.\n",
      "Delta compression using up to 4 threads.\n",
      "Compressing objects: 100% (4/4), done.\n",
      "Writing objects: 100% (5/5), 663 bytes | 663.00 KiB/s, done.\n",
      "Total 5 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To github.com:edgedown/alta17active.git\n",
      "   a1b686e..f2a6eb8  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git add ../submissions/username\n",
    "! git commit -m 'Checkpoint username' ../submissions/username/\n",
    "! git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
