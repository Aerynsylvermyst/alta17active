{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: DataDataData\n",
    "\n",
    "Here's a sample class wrapping the main abstraction, the `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guns_dataset_factory(subset='train', labelled=False):\n",
    "    \"\"\" Fetches newsgroup data and returns a Dataset. \"\"\"\n",
    "    newsgroups = fetch_20newsgroups(subset=subset)\n",
    "    \n",
    "    # Transform to guns or not.\n",
    "    labels = {i: name == 'talk.politics.guns' for i, name in enumerate(newsgroups.target_names)}\n",
    "    dataset = Dataset({text: labels[i] for text, i in zip(newsgroups.data, newsgroups.target)})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "pool = guns_dataset_factory(subset='train')\n",
    "test = guns_dataset_factory(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Annotation & reliability\n",
    "\n",
    "* TODO Learning curve @ben\n",
    "* TODO Agreement @ben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from samplers import Random\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def run_simulation(sampler, pool, test, seed_size=100):\n",
    "    \"\"\" Run a simulated learning-curve experiment. \"\"\"\n",
    "    # get test data\n",
    "    X_test, y_test = zip(*test.oracle_items)\n",
    "    # evaluate seed labels if present\n",
    "    print('..seed..')\n",
    "    pool.seed(seed_size)\n",
    "    yield sampler.fit_and_score(pool, X_test, y_test)\n",
    "    # sample until pool is empty, yielding train/test f1\n",
    "    for i in itertools.count():\n",
    "        batch = list(sampler(pool))\n",
    "        if not batch:\n",
    "            break\n",
    "        print('..batch {}..'.format(i))\n",
    "        for text, label in sampler(pool):\n",
    "            label = pool.get_oracle_label(text)\n",
    "            pool.add_label(text, label)\n",
    "        yield sampler.fit_and_score(pool, X_test, y_test)\n",
    "\n",
    "\n",
    "def run_n_simulations(sampler, pool, test, n=5, seed_size=3000):\n",
    "    \"\"\"\n",
    "    Run n simulated learning-curve experiments.\n",
    "    \n",
    "    sampler - an function for sampling from pool\n",
    "    pool - pool dataset (with oracle labels)\n",
    "    test - test dataset (with oracle labels)\n",
    "    n - number of experiments for confidence intervals (default=10)\n",
    "    seed_size - seed pool with this many labelled items\n",
    "    \"\"\"\n",
    "    # run simulations\n",
    "    runs = []\n",
    "    for i in range(n):\n",
    "        print('Running simulation {}..'.format(i))\n",
    "        runs.append(zip(*list(run_simulation(sampler, pool.copy, test, seed_size=seed_size))))\n",
    "    # return train_sizes, train_scores, test_scores\n",
    "    return (list(zip(*i)) for i in zip(*runs))\n",
    "\n",
    "\n",
    "# run a simulated experiment and plot learning curve\n",
    "random_sampler = Random(batch_size=3000)\n",
    "train_sizes, train_scores, test_scores = run_n_simulations(random_sampler, pool, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_sizes)\n",
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_learning_curve(train_sizes, train_scores, test_scores):\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"N training examples\")\n",
    "    plt.ylabel(\"F1 score\")\n",
    "    train_sizes_mean = np.mean(train_sizes, axis=1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(train_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes_mean, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes_mean, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.plot(train_sizes_mean, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes_mean, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "    \n",
    "\n",
    "plot_learning_curve(np.asarray(train_sizes), np.asarray(train_scores), np.asarray(test_scores))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplers\n",
    "\n",
    "For example, a random unlabelled sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually label some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotator import AnnotationPane\n",
    "from samplers import Random\n",
    "\n",
    "pane = AnnotationPane(pool, Random(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See our new labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pool.label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
